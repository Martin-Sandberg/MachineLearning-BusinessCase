{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import random            as rand                     # random number gen\n",
    "import pandas            as pd                       # data science essentials\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "\n",
    "# CART model packages\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import export_graphviz             # exports graphics\n",
    "from six import StringIO                             # saves objects in memory\n",
    "from IPython.display import Image                    # displays on frontend\n",
    "#import pydotplus                                     # interprets dot objects\n",
    "\n",
    "\n",
    "# new packages\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "\n",
    "# loading data\n",
    "apprentice = pd.read_excel( io = './Apprentice_Chef_Dataset.xlsx' )\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# text_split_feature\n",
    "#########################\n",
    "def text_split_feature(col, df, sep=' ', new_col_name='number_of_names'):\n",
    "    \"\"\"\n",
    "Splits values in a string Series (as part of a DataFrame) and sums the number\n",
    "of resulting items. Automatically appends summed column to original DataFrame.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "col          : column to split\n",
    "df           : DataFrame where column is located\n",
    "sep          : string sequence to split by, default ' '\n",
    "new_col_name : name of new column after summing split, default\n",
    "               'number_of_names'\n",
    "\"\"\"\n",
    "    \n",
    "    df[new_col_name] = 0\n",
    "    \n",
    "    \n",
    "    for index, val in df.iterrows():\n",
    "        df.loc[index, new_col_name] = len(df.loc[index, col].split(sep = ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# optimal_neighbors\n",
    "########################################\n",
    "def optimal_neighbors(X_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "X_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the X data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing X_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(X_data)\n",
    "        X_scaled           = scaler.transform(X_data)\n",
    "        X_scaled_df        = pd.DataFrame(X_scaled)\n",
    "        X_data             = X_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(X_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# display_tree\n",
    "########################################\n",
    "def display_tree(tree, feature_df, height = 500, width = 800):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    tree       : fitted tree model object\n",
    "        fitted CART model to visualized\n",
    "    feature_df : DataFrame\n",
    "        DataFrame of explanatory features (used to generate labels)\n",
    "    height     : int, default 500\n",
    "        height in pixels to which to constrain image in html\n",
    "    width      : int, default 800\n",
    "        width in pixels to which to constrain image in html\n",
    "    \"\"\"\n",
    "\n",
    "    # visualizing the tree\n",
    "    dot_data = StringIO()\n",
    "\n",
    "    \n",
    "    # exporting tree to graphviz\n",
    "    export_graphviz(decision_tree      = tree,\n",
    "                    out_file           = dot_data,\n",
    "                    filled             = True,\n",
    "                    rounded            = True,\n",
    "                    special_characters = True,\n",
    "                    feature_names      = feature_df.columns)\n",
    "\n",
    "\n",
    "    # declaring a graph object\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "\n",
    "    # creating image\n",
    "    img = Image(graph.create_png(),\n",
    "                height = height,\n",
    "                width  = width)\n",
    "    \n",
    "    return img\n",
    "\n",
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CROSS_SELL_SUCCESS             1.00\n",
       "CANCELLATIONS_BEFORE_NOON      0.16\n",
       "MOBILE_NUMBER                  0.10\n",
       "TASTES_AND_PREFERENCES         0.08\n",
       "REFRIGERATED_LOCKER            0.07\n",
       "PC_LOGINS                      0.04\n",
       "MASTER_CLASSES_ATTENDED        0.04\n",
       "PACKAGE_LOCKER                 0.04\n",
       "CONTACTS_W_CUSTOMER_SERVICE    0.04\n",
       "MEDIAN_MEAL_RATING             0.03\n",
       "AVG_PREP_VID_TIME              0.03\n",
       "LARGEST_ORDER_SIZE             0.02\n",
       "EARLY_DELIVERIES               0.02\n",
       "TOTAL_MEALS_ORDERED            0.01\n",
       "AVG_TIME_PER_SITE_VISIT        0.01\n",
       "TOTAL_PHOTOS_VIEWED            0.01\n",
       "LATE_DELIVERIES                0.01\n",
       "PRODUCT_CATEGORIES_VIEWED      0.00\n",
       "UNIQUE_MEALS_PURCH             0.00\n",
       "REVENUE                        0.00\n",
       "WEEKLY_PLAN                   -0.01\n",
       "AVG_CLICKS_PER_VISIT          -0.04\n",
       "CANCELLATIONS_AFTER_NOON      -0.05\n",
       "MOBILE_LOGINS                 -0.05\n",
       "Name: CROSS_SELL_SUCCESS, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Checking Correlations with original dataset variables ###\n",
    "\n",
    "df_corr = apprentice.corr(method='pearson').round(decimals=2)\n",
    "df_corr['CROSS_SELL_SUCCESS'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_REVENUE +\n",
      "log_TOTAL_MEALS_ORDERED +\n",
      "log_UNIQUE_MEALS_PURCH +\n",
      "log_CONTACTS_W_CUSTOMER_SERVICE +\n",
      "log_AVG_TIME_PER_SITE_VISIT +\n",
      "log_PC_LOGINS +\n",
      "log_AVG_PREP_VID_TIME +\n",
      "log_LARGEST_ORDER_SIZE +\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martinsandberg/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:726: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "### log transformations of all numeric variables ###\n",
    "\n",
    "success = apprentice['CROSS_SELL_SUCCESS']\n",
    "\n",
    "# Loop to create log-transformations of all numeric (non-binary) variables\n",
    "for i in range(len(df_corr)):\n",
    "    name = df_corr.index[i]\n",
    "    name_new = 'log_' + df_corr.index[i]\n",
    "    \n",
    "    if apprentice[name].nunique() != 2:\n",
    "        apprentice[name_new] = np.log10(apprentice[name]) # Adding log-transformed variable to dataset\n",
    "    \n",
    "        a = apprentice[name]\n",
    "        b = apprentice[name_new]\n",
    "        \n",
    "        corr_a = success.corr(a)\n",
    "        corr_b = success.corr(b)\n",
    "        \n",
    "        if abs(corr_b) > abs(corr_a): \n",
    "            print(name_new + ' +')\n",
    "            \n",
    "        else:\n",
    "            apprentice = apprentice.drop(name_new,axis=1) # If log-transformed variable doesn't have better correlation it's dropped\n",
    "        \n",
    "\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CROSS_SELL_SUCCESS                 1.00\n",
       "CANCELLATIONS_BEFORE_NOON          0.16\n",
       "MOBILE_NUMBER                      0.10\n",
       "TASTES_AND_PREFERENCES             0.08\n",
       "REFRIGERATED_LOCKER                0.07\n",
       "log_PC_LOGINS                      0.05\n",
       "log_CONTACTS_W_CUSTOMER_SERVICE    0.05\n",
       "PC_LOGINS                          0.04\n",
       "CONTACTS_W_CUSTOMER_SERVICE        0.04\n",
       "PACKAGE_LOCKER                     0.04\n",
       "MASTER_CLASSES_ATTENDED            0.04\n",
       "AVG_PREP_VID_TIME                  0.03\n",
       "log_AVG_PREP_VID_TIME              0.03\n",
       "log_LARGEST_ORDER_SIZE             0.03\n",
       "MEDIAN_MEAL_RATING                 0.03\n",
       "LARGEST_ORDER_SIZE                 0.02\n",
       "EARLY_DELIVERIES                   0.02\n",
       "log_TOTAL_MEALS_ORDERED            0.02\n",
       "log_AVG_TIME_PER_SITE_VISIT        0.02\n",
       "AVG_TIME_PER_SITE_VISIT            0.01\n",
       "TOTAL_MEALS_ORDERED                0.01\n",
       "LATE_DELIVERIES                    0.01\n",
       "TOTAL_PHOTOS_VIEWED                0.01\n",
       "log_REVENUE                        0.01\n",
       "log_UNIQUE_MEALS_PURCH             0.01\n",
       "PRODUCT_CATEGORIES_VIEWED          0.00\n",
       "UNIQUE_MEALS_PURCH                 0.00\n",
       "REVENUE                            0.00\n",
       "WEEKLY_PLAN                       -0.01\n",
       "AVG_CLICKS_PER_VISIT              -0.04\n",
       "CANCELLATIONS_AFTER_NOON          -0.05\n",
       "MOBILE_LOGINS                     -0.05\n",
       "Name: CROSS_SELL_SUCCESS, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking correlations with new variables\n",
    "\n",
    "df_corr = apprentice.corr(method='pearson').round(decimals=2)\n",
    "df_corr['CROSS_SELL_SUCCESS'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "apprentice['mobile_app'] = 0\n",
    "apprentice.loc[apprentice.MOBILE_LOGINS > 0, 'mobile_app'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "apprentice['above_10_cust_complaints'] = 0\n",
    "apprentice.loc[apprentice.CONTACTS_W_CUSTOMER_SERVICE > 10, 'above_10_cust_complaints'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "1941    2\n",
       "1942    2\n",
       "1943    2\n",
       "1944    1\n",
       "1945    2\n",
       "Name: number_of_names, Length: 1946, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Number of Names feature ###\n",
    "\n",
    "# calling text_split_feature\n",
    "text_split_feature('NAME',apprentice)\n",
    "\n",
    "\n",
    "# checking results\n",
    "apprentice['number_of_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### engaged vs not engaged customer ###\n",
    "apprentice['engaged'] = 0\n",
    "apprentice['engaged_2'] = 0\n",
    "apprentice['not_engaged'] = 0\n",
    "\n",
    "for index, value in apprentice.iterrows():\n",
    "    \n",
    "    if (apprentice.loc[index,'MASTER_CLASSES_ATTENDED'] > 0) and \\\n",
    "    (apprentice.loc[index,'TASTES_AND_PREFERENCES'] > 0) and \\\n",
    "    (apprentice.loc[index,'WEEKLY_PLAN'] > 0):\n",
    "        apprentice.loc[index,'engaged_2'] = 1\n",
    "        \n",
    "    elif (apprentice.loc[index,'MASTER_CLASSES_ATTENDED'] > 0) or \\\n",
    "    (apprentice.loc[index,'TASTES_AND_PREFERENCES'] > 0) or \\\n",
    "    (apprentice.loc[index,'WEEKLY_PLAN'] > 0):\n",
    "        apprentice.loc[index,'engaged'] = 1\n",
    "        \n",
    "    else:\n",
    "        apprentice.loc[index,'not_engaged'] = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EMAIL ADDRESSES ###\n",
    "\n",
    "# STEP 1: splitting personal emails\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in apprentice.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = apprentice.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "# converting placeholder_lst into a DataFrame \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "# email domain types\n",
    "personal_email_domains = ['gmail.com','protonmail.com','yahoo.com']\n",
    "\n",
    "# Junk domains\n",
    "junk_email_domains = ['me.com','aol.com','hotmail.com','live.com','msn.com','passport.com']\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in email_df.iloc[:,1]:\n",
    "        if domain in personal_email_domains:\n",
    "            placeholder_lst.append('personal')\n",
    "        elif domain in junk_email_domains:\n",
    "            placeholder_lst.append('junk')\n",
    "        else:\n",
    "            placeholder_lst.append('company')\n",
    "\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "apprentice['domain_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "one_hot_domain = pd.get_dummies(apprentice['domain_group'])\n",
    "apprentice = apprentice.join(one_hot_domain)\n",
    "apprentice = apprentice.drop('domain_group', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### Feature sets ###\n",
    "####################\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    " # full model\n",
    " 'logit_full'   : ['REVENUE','TOTAL_MEALS_ORDERED','UNIQUE_MEALS_PURCH','CONTACTS_W_CUSTOMER_SERVICE',\n",
    "                   'PRODUCT_CATEGORIES_VIEWED','AVG_TIME_PER_SITE_VISIT','MOBILE_NUMBER',\n",
    "                   'CANCELLATIONS_BEFORE_NOON','CANCELLATIONS_AFTER_NOON','TASTES_AND_PREFERENCES',\n",
    "                   'PC_LOGINS','MOBILE_LOGINS','WEEKLY_PLAN','EARLY_DELIVERIES','LATE_DELIVERIES',\n",
    "                   'PACKAGE_LOCKER','REFRIGERATED_LOCKER','AVG_PREP_VID_TIME','LARGEST_ORDER_SIZE',\n",
    "                   'MASTER_CLASSES_ATTENDED','MEDIAN_MEAL_RATING','AVG_CLICKS_PER_VISIT',\n",
    "                   'TOTAL_PHOTOS_VIEWED','log_REVENUE','log_TOTAL_MEALS_ORDERED','log_UNIQUE_MEALS_PURCH',\n",
    "                   'log_CONTACTS_W_CUSTOMER_SERVICE','log_AVG_TIME_PER_SITE_VISIT','log_PC_LOGINS',\n",
    "                   'log_AVG_PREP_VID_TIME','log_LARGEST_ORDER_SIZE','company','junk',\n",
    "                   'engaged','engaged_2','number_of_names'],\n",
    " \n",
    "\n",
    " # significant variables only (set 1)\n",
    " 'logit_sig'    : ['MOBILE_NUMBER','CANCELLATIONS_BEFORE_NOON','CANCELLATIONS_AFTER_NOON',\n",
    "                   'TASTES_AND_PREFERENCES','EARLY_DELIVERIES','LATE_DELIVERIES','REFRIGERATED_LOCKER',\n",
    "                   'MEDIAN_MEAL_RATING','log_REVENUE','log_TOTAL_MEALS_ORDERED','log_PC_LOGINS',\n",
    "                   'company','junk','engaged','engaged_2','number_of_names'],\n",
    "    \n",
    " # significant variables only (set 2)\n",
    " 'logit_best_logreg'  : ['MOBILE_NUMBER','CANCELLATIONS_BEFORE_NOON','TASTES_AND_PREFERENCES',\n",
    "                      'personal','junk','log_CONTACTS_W_CUSTOMER_SERVICE','engaged_2',\n",
    "                      'number_of_names','mobile_app'],\n",
    " \n",
    " # best tree variables only (set 2)   \n",
    " 'best_tree'          : ['MOBILE_NUMBER','CANCELLATIONS_BEFORE_NOON','TASTES_AND_PREFERENCES',\n",
    "                      'personal','junk','log_CONTACTS_W_CUSTOMER_SERVICE','engaged_2',\n",
    "                      'number_of_names'],\n",
    "    \n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "### scikit-learn models, creating dataframes ###\n",
    "################################################\n",
    "# train/test split with the full model\n",
    "apprentice_data = apprentice.loc[:,candidate_dict['logit_full']]\n",
    "apprentice_target = apprentice.loc[:,'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# train/test split with significant variables\n",
    "apprentice_data_sig = apprentice.loc[:,candidate_dict['logit_sig']]\n",
    "\n",
    "# train/test split with best logistic regression variables\n",
    "apprentice_data_best_logreg = apprentice.loc[:,candidate_dict['logit_best_logreg']]\n",
    "\n",
    "# train/test split with best tree variables\n",
    "apprentice_data_best_tree = apprentice.loc[:,candidate_dict['best_tree']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### Preparing datasets ###\n",
    "##########################\n",
    "\n",
    "# data for full dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            apprentice_data,\n",
    "            apprentice_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = apprentice_target)\n",
    "\n",
    "# data for logistic regression \n",
    "x_train_log, x_test_log, y_train_log, y_test_log = train_test_split(\n",
    "            apprentice_data_best_logreg,\n",
    "            apprentice_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = apprentice_target)\n",
    "\n",
    "# data for logistic regression \n",
    "x_train_tree, x_test_tree, y_train_tree, y_test_tree = train_test_split(\n",
    "            apprentice_data_best_tree,\n",
    "            apprentice_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = apprentice_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.6909\n",
      "Testing  ACCURACY: 0.6797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martinsandberg/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "### Full Dataset ###\n",
    "####################\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7279\n",
      "Testing  ACCURACY: 0.7392\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "### Significant Dataset ###\n",
    "###########################\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train_log, y_train_log)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test_log)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(x_train_log, y_train_log).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(x_test_log, y_test_log).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train_log, y_train_log).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test_log, y_test_log).round(4) # accuracy\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test_log,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)\n",
    "\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test_log, y_pred = logreg_pred).ravel()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Trees (CART Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "### Classification Trees (CART Models) ###\n",
    "##########################################\n",
    "\n",
    "# libraries for classification trees\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import export_graphviz             # exports graphics\n",
    "from six import StringIO           # saves objects in memory\n",
    "from IPython.display import Image                    # displays on frontend\n",
    "import pydotplus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Training ACCURACY: 0.8725\n",
      "Full Tree Testing ACCURACY : 0.6838\n",
      "Full Tree AUC Score: 0.6403\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "### Full Tree ###\n",
    "#################\n",
    "\n",
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train_log, y_train_log)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test_log)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train_log,\n",
    "                                                    y_train_log).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test_log,\n",
    "                                                    y_test_log).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test_log,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train_log, y_train_log).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test_log, y_test_log).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test_log,\n",
    "                                      y_score = full_tree_pred).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7539\n",
      "Testing  ACCURACY: 0.7762\n",
      "AUC Score        : 0.7133\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "### Pruned Tree ###\n",
    "###################\n",
    "\n",
    "# INSTANTIATING a classification tree object\n",
    "tree_pruned = DecisionTreeClassifier(max_depth = 4,\n",
    "                    min_samples_split = 25,\n",
    "                    random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "tree_pruned_fit = tree_pruned.fit(x_train_tree, y_train_tree)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "tree_pred = tree_pruned_fit.predict(x_test_tree)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(x_train_tree, y_train_tree).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(x_test_tree, y_test_tree).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_tree,\n",
    "                                          y_score = tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = tree_pruned_fit.score(x_train_tree, y_train_tree).round(4) # accuracy\n",
    "pruned_tree_test_score  = tree_pruned_fit.score(x_test_tree, y_test_tree).round(4) # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test_tree,\n",
    "                                        y_score = tree_pred).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test_tree, y_pred = tree_pred).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is: 15\n"
     ]
    }
   ],
   "source": [
    "# determining the optimal number of neighbors\n",
    "opt_neighbors = optimal_neighbors(apprentice_data_best_logreg,apprentice_target,response_type='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7553\n",
      "Testing  ACCURACY: 0.7454\n",
      "AUC Score        : 0.6619\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the data\n",
    "scaler.fit(apprentice_data_best_logreg)\n",
    "\n",
    "\n",
    "# TRANSFORMING the data\n",
    "x_scaled     = scaler.transform(apprentice_data_best_logreg)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "# adding labels to the scaled DataFrame\n",
    "x_scaled_df.columns = apprentice_data_best_logreg.columns\n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train_scaled, x_test_scaled, y_train, y_test = train_test_split(\n",
    "            x_scaled_df,\n",
    "            apprentice_target,\n",
    "            random_state = 219,\n",
    "            test_size = 0.25,\n",
    "            stratify = apprentice_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(x_test_scaled)\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test).round(4)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_train_score.round(4))\n",
    "print('Testing  ACCURACY:', knn_test_score.round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                y_score = knn_pred).round(4)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "knn_tn, \\\n",
    "knn_fp, \\\n",
    "knn_fn, \\\n",
    "knn_tp = confusion_matrix(y_true = y_test, y_pred = knn_pred).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "### Creating dataframe for first 4 models ###\n",
    "#############################################\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Logistic', 'Full Tree', 'Pruned Tree','KNN'],\n",
    "           \n",
    "    'AUC Score' : [logreg_auc_score, full_tree_auc_score, pruned_tree_auc_score,knn_auc_score],\n",
    "    \n",
    "    'Training Accuracy' : [logreg_train_score, full_tree_train_score,\n",
    "                           pruned_tree_train_score,knn_train_score],\n",
    "           \n",
    "    'Testing Accuracy'  : [logreg_test_score, full_tree_test_score,\n",
    "                           pruned_tree_test_score,knn_test_score],\n",
    "\n",
    "    'Confusion Matrix'  : [(logreg_tn, logreg_fp, logreg_fn, logreg_tp),\n",
    "                           (full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp),\n",
    "                           (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp),\n",
    "                           (knn_tn,knn_fp,knn_fn,knn_tp)]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### HYPERPARAMETER TUNINING ###\n",
    "###############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RandomizedSearchCV Results ###\n",
    "\n",
    "# Tuned Parameters  : {'warm_start': True, 'solver': 'newton-cg', 'C': 2.7}\n",
    "# Tuned CV AUC      : 0.6421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7286\n",
      "Testing  ACCURACY: 0.7433\n",
      "AUC Score        : 0.6485\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "### lr tuned ###\n",
    "################\n",
    "\n",
    "lr_tuned = LogisticRegression(solver = 'newton-cg',\n",
    "                                C = 2.7,\n",
    "                                warm_start = True,\n",
    "                                random_state = 219)\n",
    "\n",
    "# FITTING the training data\n",
    "lr_tuned.fit(x_train_log, y_train_log)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(x_test_log)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', lr_tuned.score(x_train_log, y_train_log).round(4))\n",
    "print('Testing  ACCURACY:', lr_tuned.score(x_test_log, y_test_log).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_log,\n",
    "                                  y_score = lr_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(x_train_log, y_train_log).round(4) # accuracy\n",
    "lr_tuned_test_score  = lr_tuned.score(x_test_log, y_test_log).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "lr_tuned_auc         = roc_auc_score(y_true  = y_test_log,\n",
    "                                     y_score = lr_tuned_pred).round(4) # auc\n",
    "\n",
    "# declaring model performance objects\n",
    "lr_train_acc = lr_tuned.score(x_train_log, y_train_log).round(4)\n",
    "lr_test_acc  = lr_tuned.score(x_test_log, y_test_log).round(4)\n",
    "lr_auc       = roc_auc_score(y_true  = y_test_log,\n",
    "                             y_score = lr_tuned_pred).round(4)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "lr_tuned_tn, \\\n",
    "lr_tuned_fp, \\\n",
    "lr_tuned_fn, \\\n",
    "lr_tuned_tp = confusion_matrix(y_true = y_test, y_pred = lr_tuned_pred).ravel()\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'             : 'Tuned LR',\n",
    "                          'Training Accuracy'  : lr_train_acc,\n",
    "                          'Testing Accuracy'   : lr_test_acc,\n",
    "                          'AUC Score'          : lr_auc,\n",
    "                          'Confusion Matrix'   : (lr_tuned_tn,\n",
    "                                                  lr_tuned_fp,\n",
    "                                                  lr_tuned_fn,\n",
    "                                                  lr_tuned_tp)},\n",
    "                          ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Classification trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RandomizedSearchCV Results ###\n",
    "\n",
    "# Tuned Decision Tree Parameters: {'splitter': 'best', 'min_samples_leaf': 4, 'max_depth': 3, 'criterion': 'gini'}\n",
    "# Best score is 0.7031819897084047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7423\n",
      "Testing  ACCURACY: 0.7721\n",
      "AUC Score        : 0.7307\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "tree_tuned = DecisionTreeClassifier(criterion = 'gini',\n",
    "                                    splitter = 'best',\n",
    "                                    min_samples_leaf = 4,\n",
    "                                    max_depth = 3,\n",
    "                                    random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "tree_tuned_fit = tree_tuned.fit(x_train_log, y_train_log)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "tree_pred = tree_tuned_fit.predict(x_test_log)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', tree_tuned_fit.score(x_train_log, y_train_log).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned_fit.score(x_test_log, y_test_log).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_log,\n",
    "                                          y_score = tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tuned_tree_train_score = tree_tuned_fit.score(x_train_log, y_train_log).round(4) # accuracy\n",
    "tuned_tree_test_score  = tree_tuned_fit.score(x_test_log, y_test_log).round(4) # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "tuned_tree_auc_score   = roc_auc_score(y_true  = y_test_log,\n",
    "                                        y_score = tree_pred).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test_log, y_pred = lr_tuned_pred).ravel()\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'             : 'Tuned Tree',\n",
    "                          'Training Accuracy'  : tuned_tree_train_score,\n",
    "                          'Testing Accuracy'   : tuned_tree_test_score,\n",
    "                          'AUC Score'          : tuned_tree_auc_score,\n",
    "                          'Confusion Matrix'   : (tuned_tree_tn, \n",
    "                                                  tuned_tree_fp, \n",
    "                                                  tuned_tree_fn, \n",
    "                                                  tuned_tree_tp)},\n",
    "                          ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new packages\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "### Random Forest ###\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = None,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8725\n",
      "Testing  ACCURACY: 0.7043\n",
      "AUC Score        : 0.6283\n"
     ]
    }
   ],
   "source": [
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train_log, y_train_log)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test_log)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train_log, y_train_log).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test_log, y_test_log).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_log,\n",
    "                                          y_score = rf_default_fit_pred).round(4))\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test_log, y_pred = rf_default_fit_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "rf_train_acc = rf_default_fit.score(x_train_log, y_train_log).round(4)\n",
    "rf_test_acc  = rf_default_fit.score(x_test_log, y_test_log).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test_log,\n",
    "                             y_score = rf_default_fit_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Random Forest (Full)',\n",
    "                           'Training Accuracy'  : rf_train_acc,\n",
    "                           'Testing Accuracy'   : rf_test_acc,\n",
    "                           'AUC Score'          : rf_auc,\n",
    "                           'Confusion Matrix'   : (rf_tn,\n",
    "                                                   rf_fp,\n",
    "                                                   rf_fn,\n",
    "                                                   rf_tp)},\n",
    "                          ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RandomizedSearchCV Results ###\n",
    "\n",
    "# RandomForestClassifier(bootstrap=False, criterion='entropy', n_estimators=600,random_state=219, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tuned Training ACCURACY: 0.8677\n",
      "Forest Tuned Testing  ACCURACY: 0.7433\n",
      "Forest Tuned AUC Score        : 0.6349\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "forest_tuned = RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='entropy', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=11, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=600,\n",
    "                       n_jobs=None, oob_score=False, random_state=219,\n",
    "                       verbose=0, warm_start=True)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "forest_tuned_fit = forest_tuned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                   y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "# declaring model performance objects\n",
    "tuned_rf_train_acc = forest_tuned_fit.score(x_train, y_train).round(4)\n",
    "tuned_rf_test_acc  = forest_tuned_fit.score(x_test, y_test).round(4)\n",
    "tuned_rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                                   y_score = forest_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Tuned Random Forest (Full)',\n",
    "                           'Training Accuracy'  : tuned_rf_train_acc,\n",
    "                           'Testing Accuracy'   : tuned_rf_test_acc,\n",
    "                           'AUC Score'          : tuned_rf_auc,\n",
    "                           'Confusion Matrix'   : (tuned_rf_tn,\n",
    "                                                   tuned_rf_fp,\n",
    "                                                   tuned_rf_fn,\n",
    "                                                   tuned_rf_tp)},\n",
    "                          ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "### Gradient Boosted Machines ###\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8465\n",
      "Testing ACCURACY : 0.7495\n",
      "AUC Score        : 0.6717\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "### GBM Default ###\n",
    "###################\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 3,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_default_fit = full_gbm_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4))\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "gbm_default_tn, \\\n",
    "gbm_default_fp, \\\n",
    "gbm_default_fn, \\\n",
    "gbm_default_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_default_pred).ravel()\n",
    "\n",
    "# declaring model performance objects\n",
    "gbm_train_acc = full_gbm_default_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = full_gbm_default_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = full_gbm_default_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'       : 'GBM (Full)',\n",
    "                          'Training Accuracy' : gbm_train_acc,\n",
    "                          'Testing Accuracy'  : gbm_test_acc,\n",
    "                          'AUC Score'         : gbm_auc,\n",
    "                          'Confusion Matrix'  : (gbm_default_tn,\n",
    "                                                 gbm_default_fp,\n",
    "                                                 gbm_default_fn,\n",
    "                                                 gbm_default_tp)},\n",
    "                          ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Gradient Booster Classififer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RandomizedSearchCV Results ###\n",
    "\n",
    "# Tuned Parameters  : {'warm_start': True, 'n_estimators': 125, 'max_depth': 1, 'learning_rate': 0.7000000000000001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7999\n",
      "Testing  ACCURACY: 0.7433\n",
      "AUC Score        : 0.6638\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "gbm_tuned = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.7000000000000001, loss='deviance',\n",
    "                           max_depth=1, max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=125,\n",
    "                           n_iter_no_change=None, presort='deprecated',\n",
    "                           random_state=219, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=True)\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "gbm_tuned_fit = gbm_tuned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "# declaring model performance objects\n",
    "gbm_train_acc = gbm_tuned_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned GBM',\n",
    "                          'Training Accuracy'  : gbm_train_acc,\n",
    "                          'Testing Accuracy'   : gbm_test_acc,\n",
    "                          'AUC Score'          : gbm_auc,\n",
    "                          'Confusion Matrix'   : (gbm_tuned_tn,\n",
    "                                                  gbm_tuned_fp,\n",
    "                                                  gbm_tuned_fn,\n",
    "                                                  gbm_tuned_tp)},\n",
    "                          ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7307</td>\n",
       "      <td>0.7423</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>(60, 96, 29, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>(84, 72, 37, 294)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GBM (Full)</td>\n",
       "      <td>0.6717</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(71, 85, 37, 294)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned GBM</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.7999</td>\n",
       "      <td>0.7433</td>\n",
       "      <td>(69, 87, 38, 293)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.7553</td>\n",
       "      <td>0.7454</td>\n",
       "      <td>(67, 89, 35, 296)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>0.7433</td>\n",
       "      <td>(60, 96, 29, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6421</td>\n",
       "      <td>0.7279</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>(58, 98, 29, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.6838</td>\n",
       "      <td>(81, 75, 79, 252)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuned Random Forest (Full)</td>\n",
       "      <td>0.6349</td>\n",
       "      <td>0.8677</td>\n",
       "      <td>0.7433</td>\n",
       "      <td>(52, 104, 21, 310)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest (Full)</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>(65, 91, 53, 278)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name  AUC Score  Training Accuracy  Testing Accuracy    Confusion Matrix\n",
       "5                  Tuned Tree     0.7307             0.7423            0.7721   (60, 96, 29, 302)\n",
       "2                 Pruned Tree     0.7133             0.7539            0.7762   (84, 72, 37, 294)\n",
       "8                  GBM (Full)     0.6717             0.8465            0.7495   (71, 85, 37, 294)\n",
       "9                   Tuned GBM     0.6638             0.7999            0.7433   (69, 87, 38, 293)\n",
       "3                         KNN     0.6619             0.7553            0.7454   (67, 89, 35, 296)\n",
       "4                    Tuned LR     0.6485             0.7286            0.7433   (60, 96, 29, 302)\n",
       "0                    Logistic     0.6421             0.7279            0.7392   (58, 98, 29, 302)\n",
       "1                   Full Tree     0.6403             0.8725            0.6838   (81, 75, 79, 252)\n",
       "7  Tuned Random Forest (Full)     0.6349             0.8677            0.7433  (52, 104, 21, 310)\n",
       "6        Random Forest (Full)     0.6283             0.8725            0.7043   (65, 91, 53, 278)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance.sort_values(by = 'AUC Score',\n",
    "                              ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model: Tuned Tree\n"
     ]
    }
   ],
   "source": [
    "print('Final Model: Tuned Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame to Excel\n",
    "model_performance.to_excel('./classification_model_performance.xlsx',\n",
    "                           index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "402px",
    "left": "1070px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
